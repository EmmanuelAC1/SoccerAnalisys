{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto\n",
    "## Vision Computacional\n",
    "## Emmanuel Antonio Cuevas\n",
    "\n",
    "El siguiente proyecto presenta análisis de videos de fútbol. Para realizar esta tarea escogimos video panorámicos tomados desde dos camaras, para tener vista completa del campo y hacer más preciso nuestro análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Las librerías que usaremos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.optimize import minimize\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from imutils import paths\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detector de Objetos\n",
    "Para esto usamos los modelos implementados y preentrenados de tensorflow. Nos apoyamos de la API de tensorflow, el siguiente código se encuentra la función para inicializar el detector y para procesar un frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorAPI:\n",
    "    def __init__(self, path_to_ckpt):\n",
    "        self.path_to_ckpt = path_to_ckpt\n",
    "\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(self.path_to_ckpt, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        self.default_graph = self.detection_graph.as_default()\n",
    "        self.sess = tf.Session(graph=self.detection_graph)\n",
    "\n",
    "        # Definite input and output Tensors for detection_graph\n",
    "        self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        # Each box represents a part of the image where a particular object was detected.\n",
    "        self.detection_boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        # Each score represent how level of confidence for each of the objects.\n",
    "        # Score is shown on the result image, together with the class label.\n",
    "        self.detection_scores = self.detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        self.detection_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        self.num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    def processFrame(self, image):\n",
    "        # Expand dimensions since the trained_model expects images to have shape: [1, None, None, 3]\n",
    "        image_np_expanded = np.expand_dims(image, axis=0)\n",
    "        # Actual detection.\n",
    "        start_time = time.time()\n",
    "        (boxes, scores, classes, num) = self.sess.run(\n",
    "            [self.detection_boxes, self.detection_scores, self.detection_classes, self.num_detections],\n",
    "            feed_dict={self.image_tensor: image_np_expanded})\n",
    "        end_time = time.time()\n",
    "\n",
    "        #print(\"Elapsed Time:\", end_time-start_time)\n",
    "\n",
    "        im_height, im_width,_ = image.shape\n",
    "        boxes_list = [None for i in range(boxes.shape[1])]\n",
    "        for i in range(boxes.shape[1]):\n",
    "            boxes_list[i] = (int(boxes[0,i,0] * im_height),\n",
    "                        int(boxes[0,i,1]*im_width),\n",
    "                        int(boxes[0,i,2] * im_height),\n",
    "                        int(boxes[0,i,3]*im_width))\n",
    "\n",
    "        return boxes_list, scores[0].tolist(), [int(x) for x in classes[0].tolist()], int(num[0])\n",
    "\n",
    "    def close(self):\n",
    "        self.sess.close()\n",
    "        self.default_graph.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dibujos\n",
    "El siguiente código es para dibujar circulos en una imágen, dado un vector de centros se dibujan sobre la imagen circulos de un radio especificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawCircles(image, centers, color = (0, 255, 0), alpha = 1, r = 5):\n",
    "    numb, _ = centers.shape\n",
    "    \n",
    "    auximg = np.zeros(image.shape)\n",
    "    np.copyto(auximg, image)\n",
    "    auximg = auximg.astype(image.dtype)\n",
    "    \n",
    "    for i in range(numb):\n",
    "        x = int(round(centers[i][0]))\n",
    "        y = int(round(centers[i][1]))\n",
    "        \n",
    "        cv2.circle(auximg, (x, y), 5, color, -1)\n",
    "        \n",
    "    image = cv2.addWeighted(image, 1 -alpha, auximg, alpha, 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones para detectar clics\n",
    "Para hacer las mediciones necesitamos puntos de referencia en la imagen, estos son seleccionados manualmente en el area de la izquierda y luego en la de la derecha. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onMouse1(event, x, y, flags, param):\n",
    "   global goal1_dst\n",
    "   if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        goal1_dst.append((x, y))\n",
    "        cv2.circle(image_aux,(x,y),5,(0,0,255),-1)\n",
    "        \n",
    "def onMouse2(event, x, y, flags, param):\n",
    "   global goal2_dst\n",
    "   if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        goal2_dst.append((x, y))\n",
    "        cv2.circle(image_aux,(x,y),5,(255,0,0),-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de penalty\n",
    "Para estimar la longitud del campo tendremos diferentes medida, escogemos la longitud tal que minimice la distancia hacia todas las posibles distancias estimadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanPenalty(x):\n",
    "    global distances\n",
    "    \n",
    "    sol = 0\n",
    "    for i in range(3):\n",
    "        sol += ( (x -distances[i])*(x -distances[i]) )\n",
    "        \n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distancia \n",
    "Para calcular la distancia a la que se encuentran dos puntos en el \"modelo real\". Proyectamos de coordenas en la imagen a coordenadas en nuestro modelo y ahí calculamos la distancia Euclideana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamos del campo a un modelo 2D y ahí calculamos las distancias\n",
    "def distance(x1, y1, x2, y2, invh):\n",
    "    pts = [[x1, y1], [x2, y2]]\n",
    "    pts = np.array([pts], dtype = float)\n",
    "    planepts = cv2.perspectiveTransform(pts, invh)\n",
    "    \n",
    "    x1 = planepts[0][0][0]\n",
    "    y1 = planepts[0][0][1]\n",
    "    x2 = planepts[0][1][0]\n",
    "    y2 = planepts[0][1][1]\n",
    "    \n",
    "    d1 = float(x1 -x2)\n",
    "    d2 = float(y1 -y1)\n",
    "    d = d1 * d1 + d2 * d2\n",
    "    return math.sqrt(d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proyectamos una imagen al centro del campo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageInField(image, name, alpha = 0.25):\n",
    "    global fieldlen, fieldorg\n",
    "    # Colocar imagen dentro del circulo central\n",
    "    asset = cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # rediminezionamos para que la altura de la imagen \n",
    "    # este dentro del circulo central\n",
    "    # Se ajusta el ancho de acuerdo al aspecto original de la imagen\n",
    "    ratio = asset.shape[1] / asset.shape[0]\n",
    "    asset = cv2.resize(asset, (int(round(183*ratio)), 183 ))\n",
    "\n",
    "    # Creamos imagen a proyectar del tamaño del campo\n",
    "    temp = np.zeros(fieldorg.shape, dtype = fieldorg.dtype)\n",
    "    center = [int(round(fieldlen / 2.0)), 450]\n",
    "\n",
    "\n",
    "    y1 = int(center[1] -asset.shape[0] / 2)\n",
    "    y2 = y1 +asset.shape[0]\n",
    "\n",
    "    x1 = int(center[0] -asset.shape[1] / 2)\n",
    "    x2 = x1 +asset.shape[1]\n",
    "    \n",
    "    # Compiamos la imagen en el centro\n",
    "    temp[y1:y2, x1:x2] = asset\n",
    "\n",
    "    # Proyectamos\n",
    "    temp = cv2.warpPerspective(temp, h, (image.shape[1], image.shape[0]))\n",
    "    output = cv2.addWeighted(image, 1, temp, alpha, 0)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking\n",
    "\n",
    "Usamos tracking para seguir a algun jugador y esimar su velocidad. Esta funcion inicializa una instancia de tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracker\n",
    "def newTracker():\n",
    "    tracker = cv2.TrackerMIL_create()\n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comienza el código principal\n",
    "\n",
    "Comenzamos abriendo el video y extrayendo el primer frame. De este seleccionamos los puntos que se mencionan en el reporte, primero del area de la izquierda y luego de la derecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vidcap = cv2.VideoCapture(sys.argv[1])\n",
    "vidcap = cv2.VideoCapture(\"./videos/soccer.mp4\")\n",
    "succes, frame = vidcap.read()\n",
    "\n",
    "width, height, _ = frame.shape\n",
    "frame = cv2.resize(frame, (1900, 975))\n",
    "\n",
    "\n",
    "image_aux = np.array(frame)\n",
    "# Calculamos los puntos de homografía para la primera porteria (izquierda)\n",
    "goal1_dst = []\n",
    "\n",
    "cv2.namedWindow('selectCornersGoal1')\n",
    "cv2.setMouseCallback('selectCornersGoal1', onMouse1)\n",
    "\n",
    "while(len(goal1_dst) < 11):\n",
    "    cv2.imshow('selectCornersGoal1', image_aux)\n",
    "    cv2.waitKey(100)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "\n",
    "# Calculamos los pnutos de homografía para la segunda porteria (derecha)\n",
    "goal2_dst = []\n",
    "\n",
    "cv2.namedWindow('selectCornersGoal2')\n",
    "cv2.setMouseCallback('selectCornersGoal2', onMouse2)\n",
    "\n",
    "while(len(goal2_dst) < 11):\n",
    "    cv2.imshow('selectCornersGoal2', image_aux)\n",
    "    cv2.waitKey(100)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "goal1_dst = np.array(goal1_dst)\n",
    "goal2_dst = np.array(goal2_dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se conocen algunas medidas que se usan en el fútbol, apartir de estas medidas estimamos la longitud del campo tomando la longitud que minimice la distancia hacia las demás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.zeros(3)\n",
    "\n",
    "distances[0] = 165.0 * (goal2_dst[0][0] -goal1_dst[0][0]) / (goal1_dst[8][0] -goal1_dst[0][0])\n",
    "distances[1] = 55.0  * (goal2_dst[1][0] -goal1_dst[1][0]) / (goal1_dst[5][0] -goal1_dst[1][0])\n",
    "distances[2] = 55.0  * (goal2_dst[4][0] -goal1_dst[4][0]) / (goal1_dst[6][0] -goal1_dst[4][0])\n",
    "\n",
    "start = distances[0]\n",
    "res = minimize(euclideanPenalty, start)\n",
    "\n",
    "fieldlen = res.x[0]\n",
    "fieldlen = int(round(fieldlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud estimada del campo:  1039\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud estimada del campo: \", fieldlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un sistema de coordenadas que corresponden a un modelo \"real\" del campo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puntos en el plano\n",
    "goal1_src = np.array( [ [0, 248.4],\n",
    "                        [0, 358.4],\n",
    "                        [0, 413.4],\n",
    "                        [0, 486.6],\n",
    "                        [0, 541.6],\n",
    "                        [55.0, 358.4],\n",
    "                        [55.0, 541.6],\n",
    "                        [110.0, 450.0], \n",
    "                        [165.0, 248.4],\n",
    "                        [165.0, 651.6],\n",
    "                        [201.5, 450.0]\n",
    "                        ] )\n",
    "\n",
    "goal2_src = np.array( [ [fieldlen, 248.4],\n",
    "                        [fieldlen, 358.4],\n",
    "                        [fieldlen, 413.4],\n",
    "                        [fieldlen, 486.6],\n",
    "                        [fieldlen, 541.6],\n",
    "                        [fieldlen -55.0, 358.4],\n",
    "                        [fieldlen -55.0, 541.6],\n",
    "                        [fieldlen -110.0, 450.0], \n",
    "                        [fieldlen -165.0, 248.4],\n",
    "                        [fieldlen -165.0, 651.6],\n",
    "                        [fieldlen -201.5, 450.0]\n",
    "                        ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimamos la matriz de homografía entre la imagen y nuestro sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcpts = []\n",
    "dstpts = []\n",
    "\n",
    "for i in range(11):\n",
    "    srcpts.append( [goal1_src[i][0], goal1_src[i][1]] )\n",
    "for i in range(11):\n",
    "    srcpts.append( [goal2_src[i][0], goal2_src[i][1]] )\n",
    "\n",
    "for i in range(11):\n",
    "    dstpts.append( [goal1_dst[i][0], goal1_dst[i][1]] )\n",
    "for i in range(11):\n",
    "    dstpts.append( [goal2_dst[i][0], goal2_dst[i][1]] )\n",
    "    \n",
    "srcpts = np.array(srcpts)\n",
    "dstpts = np.array(dstpts)\n",
    "\n",
    "# Calculamos la matriz de homografia y la matriz para revertir\n",
    "h, status = cv2.findHomography(srcpts, dstpts)\n",
    "invh, status = cv2.findHomography(dstpts, srcpts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proyectamos la imagen del modelo hacia el campo para ver que tan buena estimación es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field = cv2.imread(\"./imagenes/field.jpg\", cv2.IMREAD_COLOR)\n",
    "fieldorg = cv2.resize(field, ( int(round(fieldlen)), field.shape[1] ))\n",
    "field = np.array(fieldorg)\n",
    "\n",
    "field = drawCircles(field, goal1_src, (255, 255, 255))\n",
    "field = drawCircles(field, goal2_src, (255, 255, 255))\n",
    "\n",
    "cv2.line(field, tuple((int(goal1_src[0][0]), int(goal1_src[0][1]))), tuple((int(goal1_src[8][0]), int(goal1_src[8][1]))), (255,255,255), 3)\n",
    "cv2.line(field, tuple((int(goal1_src[8][0]), int(goal1_src[8][1]))), tuple((int(goal1_src[9][0]), int(goal1_src[9][1]))), (255,255,255), 3)\n",
    "cv2.line(field, tuple((int(goal1_src[1][0]), int(goal1_src[1][1]))), tuple((int(goal1_src[5][0]), int(goal1_src[5][1]))), (255,255,255), 3)\n",
    "cv2.line(field, tuple((int(goal1_src[5][0]), int(goal1_src[5][1]))), tuple((int(goal1_src[6][0]), int(goal1_src[6][1]))), (255,255,255), 3)\n",
    "cv2.line(field, tuple((int(goal1_src[6][0]), int(goal1_src[6][1]))), tuple((int(goal1_src[4][0]), int(goal1_src[4][1]))), (255,255,255), 3)\n",
    "cv2.line(field, tuple((int(0), int(651))), tuple((int(goal1_src[9][0]), int(goal1_src[9][1]))), (255,255,255), 3)\n",
    "\n",
    "cv2.line(field, tuple((int(goal2_src[0][0]), int(goal2_src[0][1]))), tuple((int(goal2_src[8][0]), int(goal2_src[8][1]))), (255,255,255), 3)\n",
    "cv2.line(field, tuple((int(goal2_src[8][0]), int(goal2_src[8][1]))), tuple((int(goal2_src[9][0]), int(goal2_src[9][1]))), (255,255,255), 3)\n",
    "cv2.line(field, tuple((int(goal2_src[1][0]), int(goal2_src[1][1]))), tuple((int(goal2_src[5][0]), int(goal2_src[5][1]))), (255,255,255), 3)\n",
    "cv2.line(field, tuple((int(goal2_src[5][0]), int(goal2_src[5][1]))), tuple((int(goal2_src[6][0]), int(goal2_src[6][1]))), (255,255,255), 3)\n",
    "cv2.line(field, tuple((int(goal2_src[6][0]), int(goal2_src[6][1]))), tuple((int(goal2_src[4][0]), int(goal2_src[4][1]))), (255,255,255), 3)\n",
    "cv2.line(field, tuple((int(fieldlen), int(651))), tuple((int(goal2_src[9][0]), int(goal2_src[9][1]))), (255,255,255), 3)\n",
    "\n",
    "\n",
    "cv2.imshow(\"field\", field)\n",
    "cv2.waitKey(3000)\n",
    "\n",
    "im_out = cv2.warpPerspective(field, h, (image_aux.shape[1], image_aux.shape[0]))\n",
    "\n",
    "cv2.imshow(\"field\", im_out)\n",
    "cv2.waitKey(3000)\n",
    "\n",
    "dst = cv2.addWeighted(image_aux, 0.7, im_out, 0.3,0)\n",
    "\n",
    "cv2.imshow('field',dst)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Inicializamos el mapa de calor con puros ceros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatMapI = np.zeros((field.shape[0], field.shape[1]), dtype = np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el mapa de inferencia del detector de objetos preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo para detectar jugadores\n",
    "model_path = './trained_soccer_model/frozen_inference_graph.pb'\n",
    "odapi = DetectorAPI(path_to_ckpt=model_path)\n",
    "threshold = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empezamos a procesar frame por frame\n",
    "\n",
    "Empieza la parte iterativa e interactiva. Los comandos que se pueden usar son\n",
    "\n",
    "s - Muestra una imagen en el centro del campo\n",
    "\n",
    "h - Muestra el mapa de calor del juego\n",
    "\n",
    "v - Muestra la velocidad de algun jugador al azar\n",
    "\n",
    "q - detener el video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, H = 1900, 975\n",
    "\n",
    "showImage = 0\n",
    "showMap = 0\n",
    "disVel = 0\n",
    "\n",
    "\n",
    "tracker  = cv2.TrackerMIL_create()\n",
    "\n",
    "start = []\n",
    "kalman = newKalman()\n",
    "\n",
    "fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "output_video = cv2.VideoWriter('output.avi', fourcc, fps, (W, H))\n",
    "\n",
    "duration = int(fps*5)\n",
    "vel = np.array([0, 0, 0, 0, 0, 0, 0], dtype = float)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    boxes, scores, classes, num = odapi.processFrame(frame)\n",
    "\n",
    "    players_pos = []\n",
    "    \n",
    "    aux_boxes = []\n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i] > threshold:\n",
    "            box = boxes[i]\n",
    "            # Nos quedamos con las cajas que pertenecen a jugadores\n",
    "            x = (box[1] + box[3])/2.0\n",
    "            y = box[2]\n",
    "            \n",
    "            players_pos.append( [x, y] )\n",
    "            aux_boxes.append(box)\n",
    "            \n",
    "    boxes = np.array(aux_boxes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Procesamos las posiciones de los jugadores encontrados y agregamos calor en las zonas donde se encuentran\n",
    "    players_pos = np.array([players_pos], dtype = float)\n",
    "    plane_pos = cv2.perspectiveTransform(players_pos, invh)\n",
    "    \n",
    "    temp = np.zeros((field.shape[0], field.shape[1]), dtype = np.uint8)\n",
    "    for i in range(plane_pos.shape[1]):\n",
    "        x = int( round(plane_pos[0][i][0]) )\n",
    "        y = int( round(plane_pos[0][i][1]) )\n",
    "        \n",
    "        cv2.circle(temp, (x, y), 10, 255, -1)\n",
    "        \n",
    "    heatMapI = cv2.addWeighted(heatMapI, 1, temp, 0.005, 0)\n",
    "    heatMap = cv2.applyColorMap(heatMapI, cv2.COLORMAP_JET)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Procesamos la imagen que se mostrara\n",
    "    if showImage > 0:\n",
    "        # Se muestra una imagen en el centro del campo\n",
    "        if showImage < 10:            \n",
    "            alpha = showImage * 0.25 / 10.0\n",
    "            frame = imageInField(frame, \"./imagenes/UGTO.png\", alpha)\n",
    "        else:\n",
    "            frame = imageInField(frame, \"./imagenes/UGTO.png\")\n",
    "        showImage -= 1\n",
    "        \n",
    "    elif showMap > 0:\n",
    "        # Se muestra el mapa de calor en el campo\n",
    "        alpha = 0.3\n",
    "        \n",
    "        if showMap < 10:\n",
    "            alpha = showMap * 0.3 / 10.0\n",
    "            \n",
    "        heatMap = cv2.warpPerspective(heatMap, h, (frame.shape[1], frame.shape[0]))\n",
    "        frame = cv2.addWeighted(frame, 1, heatMap, alpha,0)\n",
    "        showMap -= 1\n",
    "        \n",
    "    elif disVel > 0:\n",
    "        # Se muestra la velocidad de un jugador al azar\n",
    "        prevx = trackerbox[0] +trackerbox[2]/2.0\n",
    "        prevy = trackerbox[1] +trackerbox[3]\n",
    "        \n",
    "        success, trackerbox = tracker.update(frame)\n",
    "        \n",
    "        \n",
    "        if success:\n",
    "            p1 = (int( round(trackerbox[0]) ), int( round(trackerbox[1]) ))\n",
    "            p2 = (int( round(trackerbox[0]) + trackerbox[2]), int( round(trackerbox[1] + trackerbox[3]) ))\n",
    "            \n",
    "            posx = (p1[0] +p2[0])/2.0\n",
    "            posy = p2[1]\n",
    "            \n",
    "            dist = distance(prevx, prevy, posx, posy, invh)\n",
    "            \n",
    "            # Se toma la mediana de las últimas aproximaciones de velocidad\n",
    "            vel[0] = vel[1]\n",
    "            vel[1] = vel[2]\n",
    "            vel[2] = vel[3]\n",
    "            vel[3] = vel[4]\n",
    "            vel[4] = (dist * fps * 3.6) / 10.0 \n",
    "            \n",
    "            if (duration -disVel)%3 == 0:\n",
    "                prevvel = currvel\n",
    "                currvel = np.median(vel)\n",
    "                currvel = round((currvel +prevvel) / 2.0, 2)\n",
    "            \n",
    "            # Se muestra la velocidad sobre el jugador\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            TxtVel = \"v: \" + str(currvel) + \"km/h\"\n",
    "            cv2.putText(frame, TxtVel, p1, font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "            \n",
    "        disVel -= 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Se muestra el frame en pantalla y se almacena en un video\n",
    "    output_video.write(frame)\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # A continuacion se preprocesan las instrucciones que se hayan dado desde teclado\n",
    "    # Operaciones validas desde teclado\n",
    "    #        q - detener \n",
    "    #        s - mostrar imagen en el centro del campo (duracion 100 frames)\n",
    "    #        h - mostrar mapa de calor \n",
    "    #        v - velocidad de un jugador \n",
    "    # No se muestra mas de uno a la vez\n",
    "    \n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif key & 0xFF == ord('s'):\n",
    "        if showImage == 0 and showMap == 0 and disVel == 0:\n",
    "            showImage = duration\n",
    "    elif key & 0xFF == ord('h'):\n",
    "        if showImage == 0 and showMap == 0 and disVel == 0:\n",
    "            showMap = duration\n",
    "    elif key & 0xFF == ord('v'):\n",
    "        if showImage == 0 and showMap == 0 and disVel == 0:\n",
    "            disVel = duration\n",
    "            \n",
    "            x = random.randint(0, boxes.shape[0])\n",
    "            trackerbox = list( boxes[x] )\n",
    "            \n",
    "            trackerbox[2] = trackerbox[2] -trackerbox[0]\n",
    "            trackerbox[3] = trackerbox[3] -trackerbox[1]\n",
    "            \n",
    "            trackerbox[0], trackerbox[1] = trackerbox[1], trackerbox[0]\n",
    "            trackerbox[2], trackerbox[3] = trackerbox[3], trackerbox[2]\n",
    "            \n",
    "            trackerbox = tuple(trackerbox)\n",
    "            \n",
    "            tracker = newTracker()\n",
    "            tracker.init(frame, trackerbox)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Leemos el siguiente frame en el video\n",
    "    success, frame = vidcap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    # Redimenzionamos \n",
    "    frame = cv2.resize(frame, (W, H))\n",
    "    \n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
